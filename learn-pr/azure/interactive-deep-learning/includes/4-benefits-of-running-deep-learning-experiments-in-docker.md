![Docker-logotyp](../media/3-image1.PNG)

<span data-ttu-id="5ab76-102">Docker är ett verktyg som gör att du kan distribuera dina program i en sandbox-miljö för att köra på valfritt värdoperativsystem.</span><span class="sxs-lookup"><span data-stu-id="5ab76-102">Docker is a tool that allows you to deploy your applications in a sandbox to run on a host operating system of your choice.</span></span> <span data-ttu-id="5ab76-103">Det gör att du kan paketera din app med alla dess beroenden i en standardiserad enhet.</span><span class="sxs-lookup"><span data-stu-id="5ab76-103">It allows you to package your app with all of its dependencies in a standardized unit.</span></span> <span data-ttu-id="5ab76-104">Men om DSVM-basavbildningen levereras med de mest populära ramverken för djupinlärning förinstallerade, varför ska du då använda Docker?</span><span class="sxs-lookup"><span data-stu-id="5ab76-104">But if the DSVM base image comes with the most popular deep learning frameworks already pre-installed, why would you use Docker?</span></span>

<span data-ttu-id="5ab76-105">När utvecklare försöker köra djupinlärningsuppgifter står de inför utmaningar om beroenden.</span><span class="sxs-lookup"><span data-stu-id="5ab76-105">When attempting to run deep learning tasks, developers find themselves facing dependency issues.</span></span> <span data-ttu-id="5ab76-106">Exempel:</span><span class="sxs-lookup"><span data-stu-id="5ab76-106">For example:</span></span> 

- <span data-ttu-id="5ab76-107">Tvingas skapa anpassade paket – djupinlärningsforskare tenderar att tänka mindre på produktion när de publicerar kod i GitHub.</span><span class="sxs-lookup"><span data-stu-id="5ab76-107">Having to build custom packages - Deep learning researchers tend to think less about production when they publish code to GitHub.</span></span> <span data-ttu-id="5ab76-108">Om de kan få ett paket att fungera i den egna utvecklingsmiljön antar de ofta att andra också kan göra det.</span><span class="sxs-lookup"><span data-stu-id="5ab76-108">If they can get a package working on their own development environment, they often just assume that others will be able to do so as well.</span></span>
- <span data-ttu-id="5ab76-109">Versionshantering av GPU-drivrutin – CUDA är en parallell databehandlingsplattform och ett API (Application Programming Interface) som utvecklats av NVIDIA.</span><span class="sxs-lookup"><span data-stu-id="5ab76-109">GPU driver versioning - CUDA is a parallel computing platform and application programming interface (API) developed by NVIDIA.</span></span> <span data-ttu-id="5ab76-110">Med det kan utvecklare använda en CUDA-aktiverad grafikprocessor (GPU) för allmän bearbetning.</span><span class="sxs-lookup"><span data-stu-id="5ab76-110">It allows developers to use a CUDA-enabled graphics processing unit (GPU) for general-purpose processing.</span></span> <span data-ttu-id="5ab76-111">Vissa versioner av Tensorflow fungerar inte med CUDA-versioner över 9.1.</span><span class="sxs-lookup"><span data-stu-id="5ab76-111">Certain versions of Tensorflow will not work with versions of CUDA above 9.1.</span></span> <span data-ttu-id="5ab76-112">Andra ramverk, till exempel PyTorch, verkar fungera bättre med senare versioner av CUDA.</span><span class="sxs-lookup"><span data-stu-id="5ab76-112">Other frameworks, such as PyTorch, seem to perform better with later versions of CUDA.</span></span>

<span data-ttu-id="5ab76-113">För att undvika dessa problem och för att öka kodens användbarhet kan du använda Docker eller dess GPU-variant NVIDIA Docker för att hantera och köra djupinlärningsprojekt.</span><span class="sxs-lookup"><span data-stu-id="5ab76-113">To get around these issues and to increase the usability of code, you can use Docker or its GPU variant NVIDIA Docker to manage and run deep learning projects.</span></span> 

<!--Quiz 
What is CUDA? 
What versioning issues do deep learning engineers deal with? -->